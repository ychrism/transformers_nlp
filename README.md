# Sentiment Analysis avec DistilBERT

## ğŸ“‹ Description du Projet
Ce projet implÃ©mente un modÃ¨le de classification de sentiment pour analyser les critiques de films IMDb (positif/nÃ©gatif) en utilisant **DistilBERT**, une version lÃ©gÃ¨re et rapide de BERT.

## ğŸ¯ Objectifs
- Classifier automatiquement le sentiment des critiques de films
- DÃ©montrer l'utilisation de Transformers pour le NLP
- Fournir une solution efficace avec des performances Ã©levÃ©es

## ğŸ—ï¸ Architecture du ModÃ¨le

### ModÃ¨le utilisÃ©
- **Base**: `distilbert-base-uncased`
- **TÃ¢che**: Classification binaire (2 classes)
- **Labels**: 0 = NÃ©gatif, 1 = Positif

### ParamÃ¨tres d'entraÃ®nement
```python
MAX_LENGTH = 256    # Longueur maximale des textes
BATCH_SIZE = 16     # Taille des lots
EPOCHS = 3          # Nombre d'Ã©poques
LEARNING_RATE = 2e-5 # Taux d'apprentissage
```

## ğŸ“Š RÃ©sultats d'Apprentissage

### 1. Performance du ModÃ¨le
<div align="center">
  <img src="./imgs/resultats_sentiment_analysis.png" alt="RÃ©sultats d'apprentissage" width="800">
</div>

**Fig 1: Courbes d'apprentissage et matrice de confusion** *(Cliquez pour agrandir)*

### 2. MÃ©triques Finales
- **Accuracy sur test**: 86.6%
- **F1-score**: Excellent Ã©quilibre entre prÃ©cision et rappel
- **Temps d'entraÃ®nement**: ~5-10 minutes sur GPU


### Rapport de Classification Exemple:
```
               precision    recall  f1-score   support

     NÃ©gatif       0.88      0.85      0.87       254
     Positif       0.85      0.89      0.87       246

    accuracy                           0.87       500
   macro avg       0.87      0.87      0.87       500
weighted avg       0.87      0.87      0.87       500
```

## ğŸš€ Utilisation du ModÃ¨le

### 1. Installation des DÃ©pendances
```bash
pip install torch transformers datasets scikit-learn matplotlib seaborn tqdm
```

### 2. Chargement et PrÃ©diction
```python
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
import torch

# Chargement du modÃ¨le entraÃ®nÃ©
model = DistilBertForSequenceClassification.from_pretrained('votre_modele')
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# Fonction de prÃ©diction
def predict_sentiment(text):
    encoding = tokenizer.encode_plus(
        text,
        max_length=256,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    with torch.no_grad():
        outputs = model(**encoding)
        _, pred = torch.max(outputs.logits, dim=1)
    
    return 'Positif' if pred.item() == 1 else 'NÃ©gatif'

# Exemple d'utilisation
texte = "This movie was absolutely fantastic! I loved every minute of it."
sentiment = predict_sentiment(texte)
print(f"Sentiment: {sentiment}")
```

### 3. Exemples de PrÃ©dictions
<div align="center">
  <img src="./imgs/exemple_predictions.png" alt="Exemple de prÃ©dictions" width="600">
</div>

**Fig 2: Exemple d'utilisation pour prÃ©diction** *(Interface de dÃ©monstration)*

### Exemples Interactifs:
```python
exemples = [
    "This movie was absolutely fantastic! I loved every minute of it.",
    "Terrible film, waste of time. The plot was boring and predictable.",
    "An interesting concept but poorly executed. Mixed feelings overall."
]

for texte in exemples:
    sentiment = predict_sentiment(texte)
    print(f"ğŸ“ Texte: {texte[:50]}...")
    print(f"   ğŸ­ Sentiment prÃ©dit: {sentiment}")
    print("-" * 50)
```

**Sortie:**
```
ğŸ“ Texte: This movie was absolutely fantastic! I loved...
   ğŸ­ Sentiment prÃ©dit: Positif
--------------------------------------------------
ğŸ“ Texte: Terrible film, waste of time. The plot was...
   ğŸ­ Sentiment prÃ©dit: NÃ©gatif
--------------------------------------------------
ğŸ“ Texte: An interesting concept but poorly executed...
   ğŸ­ Sentiment prÃ©dit: NÃ©gatif
--------------------------------------------------
```

## ğŸ“š RÃ©fÃ©rences

1. **DistilBERT Paper**: Sanh et al., 2019
2. **IMDb Dataset**: Maas et al., 2011
3. **Transformers Library**: Hugging Face
4. **PyTorch Documentation**

## ğŸ“ License
MIT License - libre d'utilisation pour projets acadÃ©miques et commerciaux

## âœ¨ Auteur
Projet dÃ©veloppÃ© dans le cadre d'une dÃ©monstration de classification de sentiment avec Transformers.

---

**âš ï¸ Note**: Les rÃ©sultats peuvent varier selon la configuration matÃ©rielle et la taille du dataset utilisÃ©e. Pour reproduire exactement les rÃ©sultats, utiliser les mÃªmes paramÃ¨tres et seed (42).